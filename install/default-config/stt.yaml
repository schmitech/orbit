# Speech-to-Text (STT) Configuration
# Global STT settings and provider-specific configurations

stt:
  provider: "openai"       # Global default STT provider: whisper, openai, google, gemini, ollama
  enabled: false             # Global STT enable/disable

# STT Provider-specific configurations
stt_providers:
  whisper:
    # Direct integration with OpenAI's open-source Whisper (https://github.com/openai/whisper)
    # This runs Whisper locally on your machine - no API costs, completely free!
    # Requires: pip install openai-whisper
    enabled: false
    # Model size selection (trade-off between speed and accuracy)
    # tiny: ~39M params, ~32x faster, ~1GB VRAM - Fast but less accurate
    # base: ~74M params, ~16x faster, ~1GB VRAM - Good for quick transcription
    # small: ~244M params, ~6x faster, ~2GB VRAM - **RECOMMENDED** - Best balance
    # medium: ~769M params, ~2x faster, ~5GB VRAM - High quality
    # large-v3: ~1550M params, 1x speed, ~10GB VRAM - Best accuracy
    model_size: "base"  # Options: tiny, base, small, medium, large-v3

    # Device selection
    device: "auto"  # Options: auto, cpu, cuda
    # - auto: Automatically use GPU if available, otherwise CPU
    # - cpu: Force CPU usage (slower but works on any machine)
    # - cuda: Force GPU usage (requires NVIDIA GPU + CUDA)

    # Compute type (affects speed/memory)
    compute_type: "default"  # Options: default, int8, float16
    # - default: Standard precision
    # - int8: 8-bit quantization (faster, less VRAM, slight quality loss)
    # - float16: Half precision (faster on GPU, less VRAM)

    # Default language (null = auto-detect)
    language: null  # Options: null (auto), "en", "es", "fr", "de", etc. (99 languages supported)

    # Default task
    task: "transcribe"  # Options: transcribe, translate
    # - transcribe: Convert speech to text in original language
    # - translate: Convert speech to English text (Whisper can only translate TO English)

    # Timeout configuration (local processing, so timeouts are less critical)
    timeout:
      connect: 5000    # 5 seconds (local connection)
      total: 300000    # 5 minutes (for very long audio files)

    # Retry configuration
    retry:
      enabled: false   # Usually not needed for local processing
      max_retries: 1
      initial_wait_ms: 1000
      max_wait_ms: 5000
      exponential_base: 2

  openai:
    enabled: false
    api_key: ${OPENAI_API_KEY}
    api_base: "https://api.openai.com/v1"
    # STT configuration
    stt_model: "whisper-1"  # OpenAI Whisper model for transcription
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  google:
    enabled: false
    api_key: ${GOOGLE_API_KEY}
    # STT configuration
    stt_model: "latest_long"  # Google Speech-to-Text model
    stt_language_code: "en-US"  # Default language code
    stt_sample_rate: 16000  # Audio sample rate in Hz
    stt_encoding: "LINEAR16"  # Audio encoding: LINEAR16, FLAC, MULAW, AMR, AMR_WB, OGG_OPUS, SPEEX_WITH_HEADER_BYTE
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  gemini:
    # Gemini - Google's multimodal AI model with native audio support
    # Requires: pip install google-genai (NOT google-generativeai)
    enabled: false
    api_key: ${GOOGLE_API_KEY}
    # STT configuration
    stt_model: "gemini-2.5-pro"  # Use a standard multi-modal model for transcription
    # Transport configuration
    transport: "rest"  # Use REST to avoid gRPC/ALTS warnings
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds
      total: 90000     # 90 seconds
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  ollama:
    enabled: false
    base_url: "http://localhost:11434"
    # STT configuration
    stt_model: "whisper"  # Ollama model for STT (e.g., whisper, faster-whisper)
    stream: false
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
      warmup: 60000    # 1 minute for initial warmup
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  # Placeholder providers (no STT support)
  elevenlabs:
    enabled: false  # ElevenLabs is TTS-only, no STT support
    stt_model: null
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds
      total: 90000     # 90 seconds
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  coqui:
    enabled: false  # Coqui is TTS-only, no STT support
    stt_model: null
    # Timeout configuration
    timeout:
      connect: 5000    # 5 seconds (local connection)
      total: 120000    # 2 minutes
    # Retry configuration
    retry:
      enabled: false
      max_retries: 1
      initial_wait_ms: 1000
      max_wait_ms: 5000
      exponential_base: 2

  vllm:
    enabled: false  # vLLM Orpheus is TTS-only in current config
    stt_model: null  # Set to STT model name if available
    host: "3.96.176.183"
    port: 8000
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds
      total: 120000    # 2 minutes
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  anthropic:
    enabled: false  # Placeholder - Anthropic doesn't have native audio APIs yet
    api_key: ${ANTHROPIC_API_KEY}
    api_base: "https://api.anthropic.com/v1"
    stt_model: null
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds
      total: 90000     # 90 seconds
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  cohere:
    enabled: false  # Placeholder - Cohere doesn't have native audio APIs yet
    api_key: ${COHERE_API_KEY}
    api_base: "https://api.cohere.ai/v2"
    stt_model: null
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds
      total: 90000     # 90 seconds
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2
