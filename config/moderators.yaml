moderations:
  openai:
    api_key: ${OPENAI_API_KEY}
    model: "omni-moderation-latest"
  anthropic:
    api_key: ${ANTHROPIC_API_KEY}
    model: "claude-3-haiku-20240307"
    temperature: 0.0
    max_tokens: 100  # Increased from 10 to allow full JSON response
    batch_size: 5
  ollama:
    base_url: "http://localhost:11434"
    model: "llama-guard3:1b"
    temperature: 0.0
    top_p: 1.0
    max_tokens: 100  # Increased from 50 to allow full JSON response
    batch_size: 1