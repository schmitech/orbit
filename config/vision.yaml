# Global vision configuration
vision:
  provider: "ollama"  # Default vision provider: openai, gemini, anthropic
  enabled: true       # Whether vision processing is enabled globally

# Provider-specific configurations
visions:
  openai:
    enabled: true
    api_key: ${OPENAI_API_KEY}
    api_base: "https://api.openai.com/v1"
    model: "gpt-5"
    temperature: 0.0
    max_tokens: 1000
    stream: false
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  gemini:
    enabled: true
    api_key: ${GOOGLE_API_KEY}
    model: "gemini-2.5-flash"
    temperature: 0.0
    top_p: 0.8
    top_k: 20
    max_tokens: 1000
    stream: false
    transport: "rest"  # Use REST to avoid gRPC/ALTS warnings
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  anthropic:
    enabled: true
    api_key: ${ANTHROPIC_API_KEY}
    api_base: "https://api.anthropic.com/v1"
    model: "claude-3-5-sonnet-20241022"
    temperature: 0.0
    max_tokens: 1000
    stream: false
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

  ollama:
    enabled: true
    base_url: "http://localhost:11434"
    model: "qwen3-vl:8b"
    temperature: 0.0
    max_tokens: 1000
    stream: false
    think: false
    # Timeout configuration
    timeout:
      connect: 15000   # 15 seconds (increased for slow networks)
      total: 90000     # 90 seconds (increased to handle concurrent API calls + retries)
      warmup: 60000    # 1 minute for initial warmup
    # Retry configuration
    retry:
      enabled: true
      max_retries: 3
      initial_wait_ms: 1000
      max_wait_ms: 30000
      exponential_base: 2

